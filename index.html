<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Digital humanities research project exploring [your topic]">
    <meta name="author" content="Your Name">
    <title>TROS Audience Perceptions | WRIT 20833</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <nav>
        <ul>
            <li><a href="#overview">Project Overview</a></li>
            <li><a href="#question">Research Question</a></li>
            <li><a href="#data">Data & Methods</a></li>
            <li><a href="#group">Group Roles</a></li>
            <li><a href="#analysis">Results & Analysis</a></li>
            <li><a href="#findings">Findings</a></li>
            <li><a href="#reflection">Reflection</a></li>
        </ul>
    </nav>

    <header>
        <h1>Audience Perceptions of <em>Star Wars: The Rise of Skywalker</em></h1>
        <p>David, Cora, TJ, & Sam | WRIT 20833 | Fall 2025</p>
    </header>

    <main>
        <section id="overview">
            <h2>Project Overview</h2>
            <p>
                Our project is focused on the entertainment industry and audience reactions to films. We are particularly interested in the effect that movie trailers can have on audience perceptions and beliefs about a film before it comes out, and how this can shape expectations before the movie is released. We will use the Star Wars film <em>The Rise of Skywalker</em>, released in 2019, as a case study for this. We chose the film in part because it is relatively recent and is still fresh in cultural memory, and because critic and audience reactions were so split (and for longtime fans, mostly negative). 
            </p>

        </section>
        
        <section id="question">
            <h2>Research Question</h2>
            <p>What do YouTube trailer comment sections of the movie <em>The Rise of Skywalker</em> tell us about people‚Äôs expectations for the movie vs their actual reactions, and what can this tell us about how movie trailers can sometimes mislead audiences?</p>

            <p>We hypothesize that reactions to the trailer for <em>The Rise of Skywalker</em> will be more positive than film reactions because the trailers may have misdirected audiences primarily about the role that Palpatine plays in the film. This demonstrates that movie trailers, especially trailers for major blockbuster films, tend to reveal too much or set expectations too high. In the case of the newer Star Wars movies, the trailers preyed on audience nostalgia for the original Star Wars trilogy and its actors, evoking positive feelings without actually revealing any of the plot details.
</p>
        </section>

        <section id="data">
            <h2>Data & Methods</h2>

            <h3>Dataset</h3>
            <!-- TODO: Describe your data collection and methodology -->
            <p><strong>Data Source:</strong> We collected our data from the YouTube comments section of the final <em>Rise of Skywalker</em> trailer and from audience reviews on the Rotten Tomatoes page.</p>
            <p><strong>Collection Method:</strong> Because of the sheer amount of data we had to collect for our research, we relied on Instant Data Scraper to scrape comments and reviews.</p>
            <p><strong>Dataset Size:</strong> The dataset consists of 468 YouTube comments and 561 Rotten Tomatoes audience reviews. The YouTube comments range from six to five years ago, before and immediately after the movie's release, while the Rotten Tomatoes reviews range from July 25, 2022 to as recent as October 20, 2025. This gap in time was essential for us to compare how people's perceptions of the film differed over time.</p>
            <p><strong>Ethical Considerations:</strong> Because these reviews are all public and easily accessible online, we had no qualms about scraping them for data collection purposes. It's important to note that neither YouTube nor Rotten Tomatoes shows the actual full name of the commentor/reviewer and just shows a username, so the privacy of the people who wrote these stays intact.</p>

            <h3>Analysis Methods</h3>
            <p><strong>Tools:</strong> Python (pandas, VADER, Gensim)</p>
            <ul>
                <li><strong>Term Frequency Analysis:</strong> By gathering the most dominant terms, we can better understand the common ideas of these comments. Therefore, we can better make claims as to what people are commenting/reviewing about. </li>
                <li><strong>Sentiment Analysis (VADER):</strong> We hypothesize that sentiment analysis will reveal the YouTube comments to be generally more positive than the film reviews because many of them were written before the film's release.</li>
                <li><strong>Topic Modeling (Gensim LDA):</strong> [How many topics? What did you discover?]</li>
            </ul>
        </section>

        <section id="group">
            <h2>Group Roles & Responsibilities</h2>
            <p>
                Early on, we split up the responsibilities of the project between the group members in a way that highlights our academic strengths. It was decided that David would be the data programmer due to being the most experienced and most comfortable with coding, including Python; Cora would be the website programmer due to having experience with HTML and CSS; Sam would be co-data programmer and write the final essay/copy on the website due to being the least experienced with code. Later, TJ joined our group because of scheduling conflicts with his group and we decided that he would assist with data scraping and writing as well, keeping the work as evenly split as possible.

            </p>

        </section>

        <section id="analysis">
            <h2>Results & Analysis</h2>
            <!-- TODO: Add visualizations and code snippets -->

            <h3>Sentiment Analysis Results</h3>
            <p>Using VADER sentiment analysis, I examined [describe what you analyzed]...</p>

            <!-- Single visualization with caption -->
            <figure class="viz-container">
                <img src="images/sentiment-distribution.png"
                     alt="Bar chart showing distribution of positive, negative, and neutral sentiment">
                <figcaption>Figure 1: Distribution of sentiment scores across dataset</figcaption>
            </figure>

            <h3>Code Example</h3>
            <p>Here's how I implemented the sentiment analysis using <code>vaderSentiment</code>:</p>

            <div class="code-title">sentiment_analysis.py</div>
            <pre><code>from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import pandas as pd

analyzer = SentimentIntensityAnalyzer()

# Analyze sentiment for each text
df['compound'] = df['text'].apply(
    lambda x: analyzer.polarity_scores(x)['compound']
)

# Classify sentiment
df['sentiment'] = df['compound'].apply(
    lambda x: 'positive' if x > 0.05
    else ('negative' if x < -0.05 else 'neutral')
)</code></pre>

            <h3>Topic Modeling Results</h3>
            <p>Using Gensim's LDA implementation, I identified [number] major topics...</p>

            <!-- Multiple visualizations in a grid -->
            <div class="viz-grid">
                <figure class="viz-container">
                    <img src="images/topic-model.png"
                         alt="Visualization of topic clusters from LDA analysis">
                    <figcaption>Figure 2: Topic clusters from LDA analysis</figcaption>
                </figure>

                <figure class="viz-container">
                    <img src="images/word-cloud.png"
                         alt="Word cloud showing most frequent terms">
                    <figcaption>Figure 3: Most common terms in the corpus</figcaption>
                </figure>
            </div>
        </section>

        <section id="findings">
            <h2>Key Findings</h2>
            <!-- TODO: Present your main discoveries -->

            <p>The computational analysis revealed three major insights:</p>

            <ol>
                <li><strong>Finding 1:</strong> [Describe your first key discovery]</li>
                <li><strong>Finding 2:</strong> [Describe your second key discovery]</li>
                <li><strong>Finding 3:</strong> [Describe your third key discovery]</li>
            </ol>

            <h3>Detailed Results</h3>
            <p>Breaking down the sentiment distribution:</p>

            <table class="results-table">
                <thead>
                    <tr>
                        <th>Sentiment Category</th>
                        <th>Count</th>
                        <th>Percentage</th>
                        <th>Avg. Compound Score</th>
                    </tr>
                </thead>
                <tbody>
                    <tr class="highlight">
                        <td>Positive</td>
                        <td>XXX</td>
                        <td>XX%</td>
                        <td>0.XX</td>
                    </tr>
                    <tr>
                        <td>Neutral</td>
                        <td>XXX</td>
                        <td>XX%</td>
                        <td>0.XX</td>
                    </tr>
                    <tr>
                        <td>Negative</td>
                        <td>XXX</td>
                        <td>XX%</td>
                        <td>-0.XX</td>
                    </tr>
                </tbody>
            </table>

            <h3>What Surprised Me</h3>
            <p>I initially predicted that [your assumption], but the data revealed [what actually happened]. This challenged my understanding because...</p>
        </section>

        <section id="reflection">
            <h2>Critical Reflection</h2>
            <!-- TODO: Connect to course frameworks -->

            <p>This project demonstrates what happens when coding meets culture by revealing insights that neither computational analysis nor traditional close reading could discover alone.</p>

            <h3>Integration of Methods</h3>
            <p><strong>What computational methods revealed:</strong> [Describe patterns only visible through large-scale analysis]</p>
            <p><strong>What close reading added:</strong> [Describe how interpretive work enriched the computational findings]</p>

            <div class="framework-callout">
                <h3>üìê Classification Logic</h3>
                <p>This project connects to <strong>Classification Logic</strong> by revealing how algorithmic categorization shapes our understanding of [your topic]. [Explain the connection...]</p>

                <p><em>Critical question:</em> What nuances are lost when we reduce complex cultural expressions to computational categories?</p>
            </div>

            <div class="framework-callout">
                <h3>ü§ñ AI Agency</h3>
                <p>The use of topic modeling and sentiment analysis demonstrates <strong>AI Agency</strong> concerns. While the algorithms appear to "discover" meaning, the interpretation and framing of results remains entirely human. [Explain further...]</p>
            </div>

            <h3>Limitations & Future Directions</h3>
            <p><strong>What I would do differently:</strong> [Reflect on your process]</p>
            <p><strong>Questions that remain:</strong> [What would you investigate with more time?]</p>
            <p><strong>Confidence in conclusions:</strong> [How certain are you about your findings? What caveats should readers consider?]</p>
        </section>
    </main>

    <footer>
        <p>üìä <strong>Project Materials:</strong>
            <a href="https://github.com/yourusername/project-name">View Google Colab Notebooks & Data on GitHub</a>
        </p>
        <p>&copy; 2025 Your Name | WRIT 20833: Introduction to Coding in the Humanities</p>
    </footer>
</body>
</html>
